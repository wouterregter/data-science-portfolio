{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prerequisite-cutting",
   "metadata": {},
   "source": [
    "# Kaggle: Customer Transaction Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-convenience",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-ordinance",
   "metadata": {},
   "source": [
    "First, I import the necessary models and the train and test datasets from Kaggle. Throughout the feature engineering process I run a baseline logistic regression model to check the change in baseline perfomance after each large change in feature engineering, I might therefore reference to this throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-manual",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "completed-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-lithuania",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "built-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-filter",
   "metadata": {},
   "source": [
    "### Inspecting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-indianapolis",
   "metadata": {},
   "source": [
    "We will print the heads of both the train and test sets to see what they consist of. The train and test datasets each contain 200k records with 200 features. Only the train dataset contains the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afraid-dominican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 202)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "earned-driving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 201)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-singapore",
   "metadata": {},
   "source": [
    "### Inspecting the Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-alabama",
   "metadata": {},
   "source": [
    "We will now plot the distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "starting-values",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-favorite",
   "metadata": {},
   "source": [
    "The classes are highly imbalanced so we might probably benefit from doing something about that. I tried oversampling the data using SMOTE but it significantly reduced the accuracy of the baseline model. Hence, we will leave the class imbalance like this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "designed-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To deal with the class imbalance of the target variable we will use SMOTE, a method of oversampling the data.\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#smote = SMOTE() \n",
    "#train, y = smote.fit_resample(train.drop([\"ID_code\", \"target\"], axis=1), train.target)\n",
    "#train[\"target\"] = y\n",
    "#sns.countplot(x=train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-statistics",
   "metadata": {},
   "source": [
    "### Merging the Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-aggregate",
   "metadata": {},
   "source": [
    "Next, we will merge train and test to a dataframe that we will use to preprocess both simultaneously. We save the train and test ids so we will be able to reconstruct train and test later by subsetting full. We also need the ids for the submission to Kaggle. We also save and drop the target from the full dataset, as it is only present in the train set. We also drop the ID column because we will not need it at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "figured-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train[\"ID_code\"]\n",
    "test_id = test[\"ID_code\"]\n",
    "y_train = train.target.values\n",
    "full = pd.concat([train, test])\n",
    "full = full.drop([\"target\", \"ID_code\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "traditional-superintendent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-vanilla",
   "metadata": {},
   "source": [
    "### Checking for High Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-guide",
   "metadata": {},
   "source": [
    "As there are so many features, it becomes hard to visualize all of their correlations in a heatmap. Hence, to see if there are high multicollinearity issues (correlation > 0.80) we calculate the number of values with a high multicollinearity in the correlation dataframe and subtract the number of features. We subtract the number of features because for each feature there is a correlation of 1 with itself, which will be counted as a correlation of > 0.80. The output is 0 so there do not seem to be any multicollinearity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "banner-instrument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 correlations higher than 0.80.\n"
     ]
    }
   ],
   "source": [
    "corr = full.corr()\n",
    "high_corr = np.sum(np.sum(corr > 0.80)) - full.shape[1]\n",
    "print(\"There are {} correlations higher than 0.80.\".format(high_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-financing",
   "metadata": {},
   "source": [
    "### Checking for Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-privacy",
   "metadata": {},
   "source": [
    "Next, we will check for missing values. There seem to be no missing values and nothing seems to be described on the Kaggle page about missing values, therefore, we will assume there are none at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "meaning-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the data.\n"
     ]
    }
   ],
   "source": [
    "missing_vals = np.sum(np.sum(full.isna()))\n",
    "print(\"There are {} missing values in the data.\".format(missing_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-offset",
   "metadata": {},
   "source": [
    "### Checking for Skewed Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-patio",
   "metadata": {},
   "source": [
    "We will now check if there are any skewed predictors. We will do this by creating a dataframe containing all skewness and kurtosis values for each feature. We then subset the dataframe to get the features that have skewness or kurtosis of less than -2 or more than 2. There neither are any features with high skewness nor features with high kurtosis, meaning we can assume all features are approximately normally distributed. Consequently, we do not have to worry about normalizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "forty-voluntary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 0 features with high skewness.\n",
      "The data contains 0 features with high kurtosis.\n"
     ]
    }
   ],
   "source": [
    "sk = [full[feature].skew() for feature in full]\n",
    "ku = [full[feature].kurt() for feature in full]\n",
    "feature = [feature for feature in full]\n",
    "skew_df = pd.DataFrame([feature,sk,ku]).T\n",
    "skew_df.columns = [\"feature\",\"skewness\",\"kurtosis\"]\n",
    "high_skew = skew_df[(skew_df[\"skewness\"] > 2) | (skew_df[\"skewness\"] < -2)]\n",
    "high_kurt = skew_df[(skew_df[\"kurtosis\"] > 2) | (skew_df[\"kurtosis\"] < -2)]\n",
    "print(\"The data contains {} features with high skewness.\".format(len(high_skew)))\n",
    "print(\"The data contains {} features with high kurtosis.\".format(len(high_kurt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "naughty-seventh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>var_44</td>\n",
       "      <td>-0.334506</td>\n",
       "      <td>-0.10699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>var_93</td>\n",
       "      <td>-0.241298</td>\n",
       "      <td>-0.145538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>var_81</td>\n",
       "      <td>-0.233976</td>\n",
       "      <td>-0.197273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>var_86</td>\n",
       "      <td>-0.217701</td>\n",
       "      <td>-0.241528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>var_80</td>\n",
       "      <td>-0.215633</td>\n",
       "      <td>-0.401235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>var_0</td>\n",
       "      <td>0.230559</td>\n",
       "      <td>-0.269209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>var_163</td>\n",
       "      <td>0.238993</td>\n",
       "      <td>-0.345985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>var_179</td>\n",
       "      <td>0.245241</td>\n",
       "      <td>-0.018888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>var_2</td>\n",
       "      <td>0.261597</td>\n",
       "      <td>-0.327915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>var_168</td>\n",
       "      <td>0.268065</td>\n",
       "      <td>-0.197766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  skewness  kurtosis\n",
       "44    var_44 -0.334506  -0.10699\n",
       "93    var_93 -0.241298 -0.145538\n",
       "81    var_81 -0.233976 -0.197273\n",
       "86    var_86 -0.217701 -0.241528\n",
       "80    var_80 -0.215633 -0.401235\n",
       "..       ...       ...       ...\n",
       "0      var_0  0.230559 -0.269209\n",
       "163  var_163  0.238993 -0.345985\n",
       "179  var_179  0.245241 -0.018888\n",
       "2      var_2  0.261597 -0.327915\n",
       "168  var_168  0.268065 -0.197766\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skew_df.sort_values(\"skewness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-canyon",
   "metadata": {},
   "source": [
    "### Standardizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-ordinary",
   "metadata": {},
   "source": [
    "Next, we will standardize the data. The values of the features are not extremely large but it might help nonetheless. There was a slight increase in baseline performance due to the standardization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "military-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "full = scaler.fit_transform(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-argentina",
   "metadata": {},
   "source": [
    "### Reconstructing Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-legislation",
   "metadata": {},
   "source": [
    "Now that we have applied and tested all preprocessing on the full dataset, we are ready to reconstruct our train and test set in the form of numpy arrays so we can use them as inputs in the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = train.drop([\"target\"], axis=1).values\n",
    "#y_train = train.target.values\n",
    "#X_test = test.drop([\"ID_code\"], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "encouraging-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = full[:len(train_id)]\n",
    "X_test = full[len(train_id):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-fusion",
   "metadata": {},
   "source": [
    "### Logistic Regression (Baseline Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-arrangement",
   "metadata": {},
   "source": [
    "#### Feature Engineering Baseline Impacts\n",
    "- score1: 0.911689999870584 No FE\n",
    "- score2: 0.7875982554476241 After SMOTE\n",
    "- score3: 0.9143250019957262 only standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "native-vampire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9143250019957262"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression()\n",
    "cross_val_score(reg, X_train, y_train, cv=3, scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-sunrise",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-drink",
   "metadata": {},
   "source": [
    "As the dataset is quite large (>100k records), we might be better off using an algorithm that employs gradient descent. Sklearn's SGD Classifier is perfect for this situation as it allows us to use "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
